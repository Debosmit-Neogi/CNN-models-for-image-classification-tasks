{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_Learning_InceptionV3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1OhuUkWFWRT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc708e80-5d1d-43b6-d78a-3675724d01cc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgBcS7KsFaS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "zip_path = \"/content/drive/My Drive/Projects/Image Classification/image-detect.zip\"\n",
        "zip_ref = zipfile.ZipFile(zip_path, 'r')\n",
        "zip_ref.extractall(\"/content/\")\n",
        "zip_ref.close()\n",
        "print (\"ZIP Data Extracted Successfully\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC5LEq37KCfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports for Deep Learning\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tqdm\n",
        "from tensorflow import cast\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Paths and Parameters\n",
        "train_path = \"train/\"\n",
        "val_path = \"val/images/\"\n",
        "val_labels_path = \"val/val_annotations.txt\"\n",
        "test_path = \"test/\"\n",
        "\n",
        "# Transfer Learning Model\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "transfer_model = InceptionV3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p-wmPYVVlSy",
        "colab_type": "text"
      },
      "source": [
        "# Baseline Model (128 x 128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mzskr1AnWQld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 100\n",
        "num_classes = 200\n",
        "no_epochs = 10\n",
        "target_size = (128, 128)\n",
        "input_shape = (128, 128, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erH2LBESXRRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create hash map for images and corresponding labels for Training data\n",
        "train_data = []\n",
        "for folder in sorted(os.listdir(train_path)):\n",
        "    for file in sorted(os.listdir(train_path+folder+'/images')):\n",
        "        train_data.append((folder, file))\n",
        "training_df = pd.DataFrame(train_data, columns=['label', 'id'])\n",
        "training_df['filename'] = train_path+training_df['label']+'/images/'+ training_df['id']\n",
        "\n",
        "# Create hash map for images and corresponding labels for Validation data\n",
        "validation_df = pd.read_csv(val_labels_path,sep=\"\\t\",header=None)\n",
        "validation_df.columns=[\"id\",\"label\",\"X_min\",\"X_max\",\"Y_min\",\"Y_max\"]\n",
        "validation_df['filename'] = val_path + validation_df['id']\n",
        "\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = image_generator.flow_from_dataframe(\n",
        "    dataframe=training_df,\n",
        "    directory=None,\n",
        "    x_col=\"filename\",\n",
        "    y_col=\"label\",\n",
        "    target_size =target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",   \n",
        "    shuffle=True)\n",
        "\n",
        "val_generator = image_generator.flow_from_dataframe(\n",
        "    dataframe=validation_df,\n",
        "    directory=None,\n",
        "    x_col=\"filename\",\n",
        "    y_col=\"label\",\n",
        "    target_size =target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True)    \n",
        "\n",
        "test_generator = image_generator.flow_from_directory(\n",
        "    directory=test_path,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx3XyeCwXpzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = transfer_model(weights=None,\n",
        "                            include_top=False,\n",
        "                            input_shape = input_shape)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(200,activation='softmax')(x)\n",
        "model = Model(base_model.input, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEjF2W4xXpuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"RMSprop\", loss='categorical_crossentropy', metrics=[\"accuracy\"])  \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CprezIMuaSpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath=\"model_base128.hdf5\", verbose=1, save_best_only=True, monitor=\"val_accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgcC-C6bXpk0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(train_generator, \n",
        "                    epochs=no_epochs, \n",
        "                    callbacks=[checkpointer], \n",
        "                    validation_data=val_generator, \n",
        "                    verbose = 1,\n",
        "                    workers = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-YqXBWMom4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "epochs=range(len(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sDUxnO_omlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(5,5))\n",
        "plt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', label=\"Validation Accuracy\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "fig.savefig('1.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD6JngDJomaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig2 = plt.figure(figsize=(5,5))\n",
        "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.show()\n",
        "fig2.savefig('2.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz0fzvvTffcE",
        "colab_type": "text"
      },
      "source": [
        "# Baseline Model with Data Augmentation (128 x 128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkRtRuFOfl9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 100\n",
        "num_classes = 200\n",
        "no_epochs = 10\n",
        "target_size = (128, 128)\n",
        "input_shape = (128, 128, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjMgKSXIfl5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create hash map for images and corresponding labels for Training data\n",
        "train_data = []\n",
        "for folder in sorted(os.listdir(train_path)):\n",
        "    for file in sorted(os.listdir(train_path+folder+'/images')):\n",
        "        train_data.append((folder, file))\n",
        "training_df = pd.DataFrame(train_data, columns=['label', 'id'])\n",
        "training_df['filename'] = train_path+training_df['label']+'/images/'+ training_df['id']\n",
        "\n",
        "# Create hash map for images and corresponding labels for Validation data\n",
        "validation_df = pd.read_csv(val_labels_path,sep=\"\\t\",header=None)\n",
        "validation_df.columns=[\"id\",\"label\",\"X_min\",\"X_max\",\"Y_min\",\"Y_max\"]\n",
        "validation_df['filename'] = val_path + validation_df['id']\n",
        "\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "train_generator = image_generator.flow_from_dataframe(\n",
        "    dataframe=training_df,\n",
        "    directory=None,\n",
        "    x_col=\"filename\",\n",
        "    y_col=\"label\",\n",
        "    target_size =target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",   \n",
        "    shuffle=True)\n",
        "\n",
        "val_generator = image_generator.flow_from_dataframe(\n",
        "    dataframe=validation_df,\n",
        "    directory=None,\n",
        "    x_col=\"filename\",\n",
        "    y_col=\"label\",\n",
        "    target_size =target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True)    \n",
        "\n",
        "test_generator = image_generator.flow_from_directory(\n",
        "    directory=test_path,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False)\n",
        "\n",
        "data_augmentation = tf.keras.Sequential(\n",
        "    [\n",
        "        layers.experimental.preprocessing.RandomRotation(0.3),\n",
        "        layers.experimental.preprocessing.Normalization()\n",
        "        layers.experimental.preprocessing.RandomFlip(),\n",
        "        layers.experimental.preprocessing.RandomContrast(0.3),\n",
        "        layers.experimental.preprocessing.RandomTranslation(0.2, 0.2, fill_mode='wrap', interpolation='bilinear')\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOtQmLOwfl29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = Input(input_shape)\n",
        "x = data_augmentation(inputs)\n",
        "base_model = transfer_model(weights=None,\n",
        "                            include_top=False,\n",
        "                            input_shape = input_shape)\n",
        "x = base_model(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(200,activation='softmax')(x)\n",
        "model = Model(inputs, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mORorb33flzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"RMSprop\", loss='categorical_crossentropy', metrics=[\"accuracy\"])  \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "whiUgTk6hHpo",
        "colab": {}
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath=\"model_aug128.hdf5\", verbose=1, save_best_only=True, monitor=\"val_accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtTQWhgSflvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(train_generator, \n",
        "                    epochs=no_epochs, \n",
        "                    callbacks=[checkpointer], \n",
        "                    validation_data=val_generator, \n",
        "                    verbose = 1,\n",
        "                    workers = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfb4o1mbflpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "epochs=range(len(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZgPX8abhPwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(5,5))\n",
        "plt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', label=\"Validation Accuracy\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "fig.savefig('3.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRX6aJUChSci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig2 = plt.figure(figsize=(5,5))\n",
        "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and validation loss')\n",
        "fig2.savefig('4.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CIUV-dokkMf",
        "colab_type": "text"
      },
      "source": [
        "# Baseline Model with Pretrained Weights (128 x 128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uh-B9qBbI5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 100\n",
        "num_classes = 200\n",
        "no_epochs = 10\n",
        "target_size = (128, 128)\n",
        "input_shape = (128, 128, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OQG2kt6bNmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create hash map for images and corresponding labels for Training data\n",
        "train_data = []\n",
        "for folder in sorted(os.listdir(train_path)):\n",
        "    for file in sorted(os.listdir(train_path+folder+'/images')):\n",
        "        train_data.append((folder, file))\n",
        "training_df = pd.DataFrame(train_data, columns=['label', 'id'])\n",
        "training_df['filename'] = train_path+training_df['label']+'/images/'+ training_df['id']\n",
        "\n",
        "# Create hash map for images and corresponding labels for Validation data\n",
        "validation_df = pd.read_csv(val_labels_path,sep=\"\\t\",header=None)\n",
        "validation_df.columns=[\"id\",\"label\",\"X_min\",\"X_max\",\"Y_min\",\"Y_max\"]\n",
        "validation_df['filename'] = val_path + validation_df['id']\n",
        "\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "train_generator = image_generator.flow_from_dataframe(\n",
        "    dataframe=training_df,\n",
        "    directory=None,\n",
        "    x_col=\"filename\",\n",
        "    y_col=\"label\",\n",
        "    target_size =target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",   \n",
        "    shuffle=True)\n",
        "\n",
        "val_generator = image_generator.flow_from_dataframe(\n",
        "    dataframe=validation_df,\n",
        "    directory=None,\n",
        "    x_col=\"filename\",\n",
        "    y_col=\"label\",\n",
        "    target_size =target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True)    \n",
        "\n",
        "test_generator = image_generator.flow_from_directory(\n",
        "    directory=test_path,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnoUyMnikoV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = transfer_model(weights=\"imagenet\",\n",
        "                            include_top=False,\n",
        "                            input_shape=input_shape)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(200,activation='softmax')(x)\n",
        "model_pre = Model(base_model.input, predictions)\n",
        "\"\"\"for layer in base_model.layers:\n",
        "  layer.trainable=False\"\"\"\n",
        "print (\"Model ready to be Compiled\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yxnEg8wk1eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_pre.compile(optimizer=\"RMSprop\", loss='categorical_crossentropy', metrics=[\"accuracy\"])  \n",
        "model_pre.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcaRubJfk2gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath=\"model2.hdf5\", verbose=1, save_best_only=True, monitor=\"val_accuracy\")\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "                    epochs=no_epochs, \n",
        "                    callbacks=[checkpointer], \n",
        "                    validation_data=val_generator, \n",
        "                    verbose = 1,\n",
        "                    workers = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnHgXP2j7E3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "epochs=range(len(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obGjXcKa7Fpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(5,5))\n",
        "plt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', label=\"Validation Accuracy\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "fig.savefig('5.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVzIgkJG7GEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig2 = plt.figure(figsize=(5,5))\n",
        "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and validation loss')\n",
        "fig2.savefig('6.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR-rSRmYwTN1",
        "colab_type": "text"
      },
      "source": [
        "# Baseline Model with Pretrained Weights and Freeze Layers (128 x 128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXs0Q5AybXlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 100\n",
        "num_classes = 200\n",
        "no_epochs = 10\n",
        "target_size = (128, 128)\n",
        "input_shape = (128, 128, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z53xOuLbXZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create hash map for images and corresponding labels for Training data\n",
        "train_data = []\n",
        "for folder in sorted(os.listdir(train_path)):\n",
        "    for file in sorted(os.listdir(train_path+folder+'/images')):\n",
        "        train_data.append((folder, file))\n",
        "training_df = pd.DataFrame(train_data, columns=['label', 'id'])\n",
        "training_df['filename'] = train_path+training_df['label']+'/images/'+ training_df['id']\n",
        "\n",
        "# Create hash map for images and corresponding labels for Validation data\n",
        "validation_df = pd.read_csv(val_labels_path,sep=\"\\t\",header=None)\n",
        "validation_df.columns=[\"id\",\"label\",\"X_min\",\"X_max\",\"Y_min\",\"Y_max\"]\n",
        "validation_df['filename'] = val_path + validation_df['id']\n",
        "\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "train_generator = image_generator.flow_from_dataframe(\n",
        "    dataframe=training_df,\n",
        "    directory=None,\n",
        "    x_col=\"filename\",\n",
        "    y_col=\"label\",\n",
        "    target_size =target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",   \n",
        "    shuffle=True)\n",
        "\n",
        "val_generator = image_generator.flow_from_dataframe(\n",
        "    dataframe=validation_df,\n",
        "    directory=None,\n",
        "    x_col=\"filename\",\n",
        "    y_col=\"label\",\n",
        "    target_size =target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True)    \n",
        "\n",
        "test_generator = image_generator.flow_from_directory(\n",
        "    directory=test_path,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSEbxkDmvl7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = transfer_model(weights=\"imagenet\",\n",
        "                            include_top=False,\n",
        "                            input_shape=input_shape)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(200,activation='softmax')(x)\n",
        "model_freeze = Model(base_model.input, predictions)\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable=False\n",
        "print (\"Model ready to be Compiled\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwnqcsfww2KW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_freeze.compile(optimizer=\"RMSprop\", loss='categorical_crossentropy', metrics=[\"accuracy\"])  \n",
        "model_freeze.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbT7avtWw2Hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath=\"model3.hdf5\", verbose=1, save_best_only=True, monitor=\"val_accuracy\")\n",
        "history = model_freeze.fit(train_generator, \n",
        "                    epochs=no_epochs, \n",
        "                    callbacks=[checkpointer], \n",
        "                    validation_data=val_generator, \n",
        "                    verbose = 1,\n",
        "                    workers = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTccbZse7Gn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "epochs=range(len(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck04aWQm7G7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(5,5))\n",
        "plt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', label=\"Validation Accuracy\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "fig.savefig('7.jpg')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig5pnfH57HdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig2 = plt.figure(figsize=(5,5))\n",
        "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and validation loss')\n",
        "fig2.savefig('8.jpg')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtY8261voPtm",
        "colab_type": "text"
      },
      "source": [
        "# Baseline Model - Pretrained Weights, Freezed Layers and Data Augmentation(128 x 128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0pKpBbeoUe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 100\n",
        "num_classes = 200\n",
        "no_epochs = 10\n",
        "target_size = (128, 128)\n",
        "input_shape = (128, 128, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErWez2OSpqqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create hash map for images and corresponding labels for Training data\n",
        "train_data = []\n",
        "for folder in sorted(os.listdir(train_path)):\n",
        "    for file in sorted(os.listdir(train_path+folder+'/images')):\n",
        "        train_data.append((folder, file))\n",
        "training_df = pd.DataFrame(train_data, columns=['label', 'id'])\n",
        "training_df['filename'] = train_path+training_df['label']+'/images/'+ training_df['id']\n",
        "\n",
        "# Create hash map for images and corresponding labels for Validation data\n",
        "validation_df = pd.read_csv(val_labels_path,sep=\"\\t\",header=None)\n",
        "validation_df.columns=[\"id\",\"label\",\"X_min\",\"X_max\",\"Y_min\",\"Y_max\"]\n",
        "validation_df['filename'] = val_path + validation_df['id']\n",
        "\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "train_generator = image_generator.flow_from_dataframe(\n",
        "    dataframe=training_df,\n",
        "    directory=None,\n",
        "    x_col=\"filename\",\n",
        "    y_col=\"label\",\n",
        "    target_size =target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",   \n",
        "    shuffle=True)\n",
        "\n",
        "val_generator = image_generator.flow_from_dataframe(\n",
        "    dataframe=validation_df,\n",
        "    directory=None,\n",
        "    x_col=\"filename\",\n",
        "    y_col=\"label\",\n",
        "    target_size =target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True)    \n",
        "\n",
        "test_generator = image_generator.flow_from_directory(\n",
        "    directory=test_path,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False)\n",
        "\n",
        "data_augmentation = tf.keras.Sequential(\n",
        "    [\n",
        "        layers.experimental.preprocessing.RandomRotation(0.3),\n",
        "        layers.experimental.preprocessing.Normalization()\n",
        "        layers.experimental.preprocessing.RandomFlip(),\n",
        "        layers.experimental.preprocessing.RandomContrast(0.3),\n",
        "        layers.experimental.preprocessing.RandomTranslation(0.2, 0.2, fill_mode='wrap', interpolation='bilinear')\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTlxIroJpqo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = Input(input_shape)\n",
        "x = data_augmentation(inputs)\n",
        "base_model = transfer_model(weights=\"imagenet\",\n",
        "                            include_top=False,\n",
        "                            input_shape=input_shape)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(200,activation='softmax')(x)\n",
        "model_freeze = Model(inputs, predictions)\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable=False\n",
        "print (\"Model ready to be Compiled\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VupuVVvWpqld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_freeze.compile(optimizer=\"RMSprop\", loss='categorical_crossentropy', metrics=[\"accuracy\"])  \n",
        "model_freeze.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFHHrAN_pqjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath=\"model3.hdf5\", verbose=1, save_best_only=True, monitor=\"val_accuracy\")\n",
        "history = model_freeze.fit(train_generator, \n",
        "                    epochs=no_epochs, \n",
        "                    callbacks=[checkpointer], \n",
        "                    validation_data=val_generator, \n",
        "                    verbose = 1,\n",
        "                    workers = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxGZEH9CpqgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "epochs=range(len(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skcEX0ENp6or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(5,5))\n",
        "plt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', label=\"Validation Accuracy\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "fig.savefig('9.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQwL6d6vp6ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig2 = plt.figure(figsize=(5,5))\n",
        "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and validation loss')\n",
        "fig2.savefig('10.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQYZySDwMbaV",
        "colab_type": "text"
      },
      "source": [
        "# Baseline Model (224 x 224)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-Z8PVSeLz0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 50\n",
        "num_classes = 200\n",
        "no_epochs = 10\n",
        "target_size = (224, 224)\n",
        "input_shape = (224, 224, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2qhu-KDrPtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create hash map for images and corresponding labels for Training data\n",
        "train_data = []\n",
        "for folder in sorted(os.listdir(train_path)):\n",
        "    for file in sorted(os.listdir(train_path+folder+'/images')):\n",
        "        train_data.append((folder, file))\n",
        "training_df = pd.DataFrame(train_data, columns=['label', 'id'])\n",
        "training_df['filename'] = train_path+training_df['label']+'/images/'+ training_df['id']\n",
        "\n",
        "# Create hash map for images and corresponding labels for Validation data\n",
        "validation_df = pd.read_csv(val_labels_path,sep=\"\\t\",header=None)\n",
        "validation_df.columns=[\"id\",\"label\",\"X_min\",\"X_max\",\"Y_min\",\"Y_max\"]\n",
        "validation_df['filename'] = val_path + validation_df['id']\n",
        "\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "train_generator = image_generator.flow_from_dataframe(\n",
        "    dataframe=training_df,\n",
        "    directory=None,\n",
        "    x_col=\"filename\",\n",
        "    y_col=\"label\",\n",
        "    target_size =target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",   \n",
        "    shuffle=True)\n",
        "\n",
        "val_generator = image_generator.flow_from_dataframe(\n",
        "    dataframe=validation_df,\n",
        "    directory=None,\n",
        "    x_col=\"filename\",\n",
        "    y_col=\"label\",\n",
        "    target_size =target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True)    \n",
        "\n",
        "test_generator = image_generator.flow_from_directory(\n",
        "    directory=test_path,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vmBX_ScrPqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = transfer_model(weights=None,\n",
        "                            include_top=False,\n",
        "                            input_shape = input_shape)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(200,activation='softmax')(x)\n",
        "model = Model(base_model.input, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqFiyJznrPoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"RMSprop\", loss='categorical_crossentropy', metrics=[\"accuracy\"])  \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HROsuU5erPk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpointer = ModelCheckpoint(filepath=\"model_base224.hdf5\", verbose=1, save_best_only=True, monitor=\"val_accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0yYXdCXrPi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history2 = model.fit(train_generator, \n",
        "                    epochs=no_epochs, \n",
        "                    callbacks=[checkpointer], \n",
        "                    validation_data=val_generator, \n",
        "                    verbose = 1,\n",
        "                    workers = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R2FGVaPrPe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "epochs=range(len(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw4WNTh1r1Dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(5,5))\n",
        "plt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', label=\"Validation Accuracy\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "fig.savefig('11.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qs8k8L0r1AF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig2 = plt.figure(figsize=(5,5))\n",
        "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.show()\n",
        "fig2.savefig('12.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}